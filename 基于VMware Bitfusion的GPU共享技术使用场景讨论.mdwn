# 基于VMware Bitfusion的GPU共享技术使用场景讨论

说明：此文章编写日期为 2020 年，基于 Bitfusion 2.0 版本。文中的命令可能已经不适用新版本，但其中理念依然适用。 

## 1. 背景
---
GPU作为一种加速器芯片，在机器学习，特别是深度学习中得到广泛的应用。 但是，无论是企业、学校、医院或者政府单位，决定在人工智能领域进行投入时，领导却发现：
- 投入了100万，光买设备就花了80万，工程师还经常抱怨GPU资源不够用
- 当工程师雄心勃勃打算开始干活，却发现花了一个多星期，IT环境还没有搞好

究其原因，大致有以下三个：

1. GPU采购成本比较高，而且由于技术发展的限制，在实际使用中，比较难于共享，从而导致浪费和不足的情况并存。
2. GPU的使用场景比较复杂，训练需要大量资源且需要长时间使用，在线推理需要及时响应，而开发和培训/课程实训场景的并发用户数会很多。
3. 机器学习的环境配置复杂，且通常情况下数据工程师不擅长。
    - 通常，环境涉及到GPU驱动、CUDA、程序设计语言编译器/解释器（比如python）、机器学习平台（比如TensorFlow、PyTorch）等。而且这些软件对版本都有一定的匹配要求。
    - 根据不同人员的使用习惯，有人喜欢用docker，有人喜欢直接运行命令，可能还涉及到Jupyter notebook工具的使用。
    - 很多的安装程序都需要连接到国外服务器，下载速度很慢。

>**VMware基于Bitfusion技术的方案正是来应对这样的场景和需求。**

<br/><br/>

## 2. 场景与需求
---

最近我们针对于高校的使用场景做了一个验证，和大家分享一下。 当然，虽然这是高校场景，但对于其他行业，依然具有参考价值。

在高校中，遇到的场景主要包含上课和科研。

1. 在上课场景中，通常情况下，任课老师会根据课程需要事先安装相应的软件和工具；在实际课程中，学生每人获得一个这样的环境，使用课程中相关的算法进行模型的开发和训练。在整个过程中，学生关注于机器学习的方法和算法，而不是环境的安装、配置和故障处理。
2. 在科研场景中，科研人员（包括老师和研究生）根据科研任务和场景，开发相应的模型、算法和参数，并且利用GPU进行训练和调整。

<br/><br/>

## 3. 解决方案架构
---
针对于以上需求，我们构建了以下架构的IT基础设施服务：

![architecture](./images/bf-archi.png)

图 1：整体架构图

首先构建基于Bitfusion的GPU共享池。我们通过创建4台虚拟机，每台虚拟机通过vSphere的直通技术使用2块GPU V100（32GB显存）的GPU卡。


课程场景的资源，通过Horizon虚拟桌面提供。具体流程如下：
1. 老师通过在虚拟机中安装课程所需的软件，制作课程模板。课程使用机器学习常用的Ubuntu16.04和Ubuntu18.04操作系统，并且虚拟机已经安装了Bitfusion客户端，可以将任务发送到远程的Bitfusion服务器端进行计算。
2. IT管理员通过镜像模板在上课之前发布虚拟桌面，桌面数量与学生数量保持一致，或者略多一些。
3. 学生在上课时，通过实训教室现有的PC，或者瘦客户机，或者学生自己的笔记本电脑，通过浏览器或者Horizon客户端登录到虚拟桌面，根据课程指定的任务。当需要GPU资源时，Bitfusion客户端会将任务发送到远程Bitfusion服务器端执行；当资源不足时，系统会进行排队。
4. 课程结束后，资源自动回收。

在科研场景中，科研人员如果是进行模型开发，依然可以在Horizon虚拟桌面中进行；如果是长时间执行的训练的任务，则建议通过vRealize Automation云管理平台申请已经安装并enable bitfusion的虚拟服务器。科研人员在虚拟服务器中执行相关的python代码，运行在虚拟服务器中的Bitfusion客户端会将相关的程序发送到Bitfusion服务器端执行。当然，如果科研人员希望在虚拟服务器中使用docker或者Jupyter notebook，也是没有问题的。

通过Bitfusion的Quota机制，可以给到不同的用户和场景，不同的最大可使用资源份额，以避免资源的滥用。Bitfusion也可以通过设定，断开占用GPU资源但是却没有真正使用的客户端。
<br/><br/>

## 4. 测试用例
---
在本次测试中，我们验证了以下用例：

1. 使用编辑器编写python代码，通过python命令直接运行
2. 运行python之后进入到交互命令行，运行相关命令
3. 使用Jupyter Notebook打开ipynb文件，并运行相关notebook
4. 使用Docker启动Nvidia提供的容器镜像，并进入容器内执行相应的python脚本

具体测试过程和结果如下：

### 4.1 使用编辑器编写python代码，通过python命令直接运行

我们使用TensorFlow官方的benchmark工具tf_cnn_benchmarks. 
https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks
使用cifar10数据集https://www.cs.toronto.edu/~kriz/cifar.html，模型采用resnet110，batch_size为64

原生的脚本命令命令如下：
```
python3  ./benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py  --data_format=NCHW  --batch_size=64  --model=resnet110  --variable_update=replicated  --local_parameter_device=gpu  --nodistortions --num_gpus=1  --num_batches=100  --data_dir=./benchmarks/data/cifar-10-batches-py  --data_name=cifar10  --use_fp16=False
``` 

本测试中，我们使用Bitfusion来运行。Bitfusion的具体使用方法可以参看官方文档 《在vSphere Bitfusion上运行TensorFlow的示例指南》 https://docs.vmware.com/cn/VMware-vSphere-Bitfusion/2.0/vmware-vsphere-bitfusion-20-tensorflow-example-guide.pdf。

我们尝试以下GPU份额：完整的V100GPU、1/10个GPU、1/20个GPU. 实际使用的显存分别为：32GB、3.2GB、1.6GB。本项测试的关注点在于我们究竟需要多少GPU，才可以正常运行这个TensorFlow benchmark。

我们使用如下命令调整GPU的份额：
``` 
bitfusion run -n 1 -p 1 -- python3  ./benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py  --data_format=NCHW  --batch_size=64  --model=resnet110  --variable_update=replicated  --local_parameter_device=gpu  --nodistortions --num_gpus=1  --num_batches=100  --data_dir=./benchmarks/data/cifar-10-batches-py  --data_name=cifar10  --use_fp16=False
``` 
``` 
bitfusion run -n 1 -p 0.1 -- python3  ./benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py  --data_format=NCHW  --batch_size=64  --model=resnet110  --variable_update=replicated  --local_parameter_device=gpu  --nodistortions --num_gpus=1  --num_batches=100  --data_dir=./benchmarks/data/cifar-10-batches-py  --data_name=cifar10  --use_fp16=False
``` 
``` 
bitfusion run -n 1 -p 0.05 -- python3  ./benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py  --data_format=NCHW  --batch_size=64  --model=resnet110  --variable_update=replicated  --local_parameter_device=gpu  --nodistortions --num_gpus=1  --num_batches=100  --data_dir=./benchmarks/data/cifar-10-batches-py  --data_name=cifar10  --use_fp16=False
``` 

以上所有的配置中，tf_cnn_banchmarks处理的结果均大致为：1200 images/second。当然，这个性能数据和直接使用本地的GPU还是有一些差距，主要原因是本次测试，由于条件的限制，并没有做优化。具体的优化可以参看：《VMware vSphere Bitfusion
Performance Best Practices Guide》https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/performance/bitfusion-perf-best-practices.pdf


>**如果采用0.05个GPU支持单个任务，则一块V100 GPU（32GB显存）则可以同时支持20个并发tf_cnn_benchmarks任务。 如果用户希望增加更多的并发任务，则需要调整batch_size参数。在实际应用中，由于系统提供排队机制，当单个任务执行时间不是很长的情况下，可以有更多的学生同时使用。**


### 4.2 运行Python，并进入到交互命令行，运行相关命令

此类情形，我们需要首先申请远程GPU资源，然后再运行相关的命令和脚本，最后需要释放远程的GPU资源。相关的命令可以参考Bitfusion官方文档 - 《VMware vSphere Bitfusion 用户指南》 https://docs.vmware.com/cn/VMware-vSphere-Bitfusion/2.0/vmware-vsphere-bitfusion-20-user-guide.pdf

在下面这个示例中，我们首先申请单块GPU，2048M的显存；然后进入Python交互式命令行，运行tensorflow的代码获得GPU信息；最后释放GPU。

``` bash
$ bitfusion request_gpus -n 1 -m 2048
Requested resources:
Server List: 192.168.131.36:56001
Client idle timeout: 0 min

$ bitfusion client -- python3
Python 3.6.9 (default, Jul 17 2020, 12:50:27)
[GCC 8.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import tensorflow as tf
...
>>> print(tf.test.gpu_device_name())
...
2020-09-27 18:08:42.584300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:00:00.0
totalMemory: 2.00GiB freeMemory: 1.41GiB
...
2020-09-27 18:08:42.592493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 1217 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:00:00.0, compute capability: 7.0)

/device:GPU:0
...

>>> quit();

$ bitfusion release_gpus
``` 

>从以上验证结果我们可以看到Bitfusion支持交互式Python运行方式。

### 4.3	使用Jupyter Notebook打开ipynb文件，并运行相关notebook

Jupyter Notebook 作为一个代码、输出、文档、多媒体资源整合在一起的多功能科学运算平台，深受数据科学工作者的喜爱，被广泛的应用在机器学习的各个教程中。

Jupyter Notebook 支持自定义kernel来运行代码，所以我们有机会构建基于Bitfusion的python kernel。如下图所示：

![bf-jupyternotebook](./images/bf-jupyternotebook.png)

图 2：使用Bitfusion kernel运行Jupyter Notebook​

具体的做法可以参看《Bitfusion Jupyter Integration—It’s Full of Stars》
https://blogs.vmware.com/vsphere/2020/08/bitfusion-jupyter-integration-its-full-of-stars.html

需要指出的是，kernel在定义的时候，就需要指定所用的GPU资源。所以，如果在课程中，需要使用不同大小的GPU资源，则可能需要定义多个kernel。

本次测试使用TensorFlow官方的标准教程（tutorial）中的穿戴用品的图像识别 - https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/keras/basic_classification.ipynb

>在测试中，我们发现只需要配置0.02个V100 GPU资源就可以顺利运行basic_classification的应用；也就是说，一块V100的GPU卡可以同时给到50个学生使用。

与交互式python类似，当用户在Jupyter Notebook的网页中，选定一个kernel开始运行的时候，这个kernel就占据了GPU资源，直到kernel被停止。也就是说，如同4.1中的超配（overcommit）之后的排队，在使用Jupyter Notebook时候，不能使用。

### 4.4 使用Docker启动Nvidia提供的容器镜像，并进入容器内执行相应的python脚本

随着Docker的流行，很多数据科学家也开始使用Docker。Docker的优势在于docker image中已经安装好了运行环境，用户省去了很多繁琐的安装配置工作。用户通过切换docker images也可以很容易的切换运行环境。不管是Nvidia，还是framework的供应商（比如TensorFlow），也都提供了docker images给到大家使用。当然，使用docker也带来的一些麻烦，就是用户必须要了解docker的使用。

在bitfusion结合docker的场景中，docker image 管理员需要基于官方的镜像，通过 docker build 构建基于bitfusion的docker image。比如如下的Dockerfile就是在nvcr.io/nvidia/tensorflow:19.03-py3中加入bitfusion的支持，生成新的docker image。

``` 
$ cat Dockerfile
FROM nvcr.io/nvidia/tensorflow:19.03-py3 
MAINTAINER XXX University Bitfusion

#  Set initial working directory
WORKDIR /home/bitfusion/downloads/
 
# Update package list
RUN apt-get update
 
# Install Bitfusion. Assumes deb for Ubuntu16.04
# resides in mounted directory, /pkgs
COPY bitfusion-client-ubuntu1604_2.0.0beta5-11_amd64.deb .
RUN apt-get install -y ./bitfusion-client-ubuntu1604_2.0.0beta5-11_amd64.deb
# Must run list_gpus to pull in env and tokens
RUN bitfusion list_gpus
``` 

制作新的docker image，然后通过运行docker run进入到docker进程的shell，下面用户就可以运行相关的Python代码了。
``` 
sudo docker build -t tensorflow:19.03-py3-bitfusion .
 
sudo docker run --rm --privileged --pid=host --ipc=host \
   --net=host -it \
   -v /data:/data \
   -v /dev/log:/dev/log \
   tensorflow:19.03-py3-bitfusion
``` 

具体的方式可以参看这份文档。《AI/ML, vSphere Bitfusion, and Docker Containers—A Sparkling Refreshment for Modern Apps》
https://blogs.vmware.com/vsphere/2020/06/ai-ml-vsphere-bitfusion-and-docker-containers-a-sparkling-refreshment-for-modern-apps.html

>从以上验证结果我们可以看到Bitfusion支持使用容器环境。

<br/><br/>

## 5. 方案主要优势
---
1. 使用Bitfusion统一管理所有的GPU资源，按需使用，用完自动归还，尽可能减少idle的情况，大大提升了GPU资源的使用效率
2. Bitfusion GPU共享机制对用户使用透明，用户不需要改变任何代码
3. 使用Horizon虚拟桌面和即时克隆技术，可以提供统一的环境给到学生，让学生可以专注在课程本身，而不是环境的安装和配置
4. 科研人员可以利用到更多的GPU资源，更快的完成训练任务得到反馈，提高了科研的效率

<br/><br/>

## 6. 扩展讨论
---
本方案主要解决的是学习、开发和训练的场景，依然适合于其他行业的类似场景。针对于推理场景，特别是在线推理，本架构很容易扩展支持。

![bf-training-inference](./images/bf-training-inference.png)

图 3：支持开发、训练和推理的架构

<br/><br/>

## 7. 总结
---
GPU最为一种加速器资源，在数据科学特别是机器学习场景中，被广泛采用。当前的GPU使用方式，无论是资源使用效率，还是运行环境的运维上，都存在很大的挑战。VMware的Bitfusion技术应运而生，使得GPU资源可以在多个客户端分时共享，并且可以根据应用需求灵活动态的切割显存。本文基于高校的教学和科研场景，结合VMware Horizon虚拟桌面产品和vRealize云管理平台产品，设计解决方案，并进行了相关验证，验证基本覆盖了常用的使用场景和工具。 通过扩展，该解决方案架构依然适用于其他行业。

<br/><br/>
正文完
<br/><br/>

---

参考资料：
1. vSphere Bitfusion 2.0.0 安装指南：https://docs.vmware.com/cn/VMware-vSphere-Bitfusion/2.0/vmware-vsphere-bitfusion-20-installation-guide.pdf
2. VMware vSphere Bitfusion 用户指南: https://docs.vmware.com/cn/VMware-vSphere-Bitfusion/2.0/vmware-vsphere-bitfusion-20-user-guide.pdf
3. 在 vSphere Bitfusion 上运行 TensorFlow 的示例指南: https://docs.vmware.com/cn/VMware-vSphere-Bitfusion/2.0/vmware-vsphere-bitfusion-20-tensorflow-example-guide.pdf
4. Bitfusion Jupyter Integration—It’s Full of Stars: https://blogs.vmware.com/vsphere/2020/08/bitfusion-jupyter-integration-its-full-of-stars.html
5. AI/ML, vSphere Bitfusion, and Docker Containers—A Sparkling Refreshment for Modern Apps: https://blogs.vmware.com/vsphere/2020/06/ai-ml-vsphere-bitfusion-and-docker-containers-a-sparkling-refreshment-for-modern-apps.html